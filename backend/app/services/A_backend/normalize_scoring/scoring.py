import os, json, argparse, re, yaml
from collections import defaultdict
from typing import List, Dict, Any
# (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Path ‡∏Ç‡∏≠‡∏á import ‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á - ‡πÉ‡∏ä‡πâ .skills_normalizer ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
from .skills_normalizer import normalize_skills

# ---- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ JD ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô) ----
DEFAULT_JOB_REQ = {
    "title_keywords": ["data analyst", "data engineer", "business intelligence"],
    "must_skills": ["Python", "SQL", "Tableau"],
    "nice_skills": ["Airflow", "Power BI", "Docker", "Excel"],
    # (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô - ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ JD config)
    "weights": {
        "skills": 0.40,
        "experience": 0.20,
        "title": 0.20,
        "contacts": 0.20
    }
}

# (‡πÉ‡∏ä‡πâ global variable ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö JOB_REQ ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ)
CURRENT_JOB_REQ = DEFAULT_JOB_REQ.copy()


PII_KEYS = {"email", "phone", "location", "address", "linkedin", "github", "line", "facebook"}

# ---------------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏¢‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡πÅ‡∏ï‡πà‡πÉ‡∏ä‡πâ CURRENT_JOB_REQ) ----------------
def score_title(name_or_roles: List[str]) -> float:
    text = " ".join(name_or_roles).lower()
    keywords = CURRENT_JOB_REQ.get("title_keywords", [])
    return 1.0 if any(k.lower() in text for k in keywords) else 0.0

def score_skills(norm_skills: List[str]):
    must_set = set(s.lower() for s in CURRENT_JOB_REQ.get("must_skills", []))
    nice_set = set(s.lower() for s in CURRENT_JOB_REQ.get("nice_skills", []))
    s_set = set(s.lower() for s in norm_skills) # ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤ norm_skills ‡πÄ‡∏õ‡πá‡∏ô lowercase ‡πÅ‡∏•‡πâ‡∏ß
    
    must_matches = s_set & must_set
    nice_matches = s_set & nice_set

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏®‡∏π‡∏ô‡∏¢‡πå)
    must_hit = len(must_matches) / len(must_set) if must_set else 1.0
    nice_hit = len(nice_matches) / len(nice_set) if nice_set else 1.0

    score = must_hit * 0.8 + nice_hit * 0.2

    # ‡∏´‡∏≤ Gaps (‡∏™‡∏Å‡∏¥‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ ‡πÅ‡∏ï‡πà‡∏Ç‡∏≤‡∏î‡πÑ‡∏õ - ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ö‡∏ö case-insensitive)
    missing_must = sorted(list(must_set - s_set))
    # (‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô Case ‡πÄ‡∏î‡∏¥‡∏°‡∏à‡∏≤‡∏Å JD ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•)
    original_must_map = {s.lower(): s for s in CURRENT_JOB_REQ.get("must_skills", [])}
    gaps = [original_must_map.get(m, m) for m in missing_must] # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ Gaps ‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏¥‡∏°

    # ‡∏´‡∏≤ matched skills (‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏¥‡∏°‡∏à‡∏≤‡∏Å JD ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà Normalize ‡πÅ‡∏•‡πâ‡∏ß)
    original_nice_map = {s.lower(): s for s in CURRENT_JOB_REQ.get("nice_skills", [])}
    matched_skills_orig_case = [original_must_map.get(m, m) for m in must_matches] + \
                               [original_nice_map.get(n, n) for n in nice_matches]
    
    # (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á: ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ matched skills ‡∏ï‡∏≤‡∏° Case ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô norm_skills)
    norm_skills_map = {s.lower(): s for s in norm_skills}
    final_matched = []
    seen_lower = set()
    for skill_lower in (must_matches | nice_matches): # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏à‡∏≤‡∏Å set ‡∏Ç‡∏≠‡∏á lowercase ‡∏ó‡∏µ‡πà match
         if skill_lower in norm_skills_map: # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÉ‡∏ô norm_skills
              final_matched.append(norm_skills_map[skill_lower]) # ‡πÉ‡∏ä‡πâ Case ‡∏à‡∏≤‡∏Å norm_skills
              seen_lower.add(skill_lower)
         # (Fallback: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô norm_skills ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡πÉ‡∏ô JD map - ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏ñ‡πâ‡∏≤ normalize ‡∏ñ‡∏π‡∏Å)
         elif skill_lower in original_must_map and skill_lower not in seen_lower:
              final_matched.append(original_must_map[skill_lower])
              seen_lower.add(skill_lower)
         elif skill_lower in original_nice_map and skill_lower not in seen_lower:
              final_matched.append(original_nice_map[skill_lower])
              seen_lower.add(skill_lower)

    return score, gaps, sorted(list(set(final_matched))) # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ unique

def estimate_years(experiences: List[dict]) -> int:
    # (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á: ‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏à‡∏≤‡∏Å date range ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    years = 0
    if experiences:
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏¥‡∏°: ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡πâ‡∏≠‡∏ô
        years = len(experiences)
        # (‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏´‡∏°‡πà - ‡∏•‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å start/end - ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà implement)
    return min(5, years) # Cap ‡∏ó‡∏µ‡πà 5 ‡∏õ‡∏µ

def score_contacts(contacts: dict | None) -> float:
    if not contacts: return 0.0
    ok = int(bool(contacts.get("email"))) + int(bool(contacts.get("phone")))
    # (‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç location ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
    # ok += int(bool(contacts.get("location")))
    return 1.0 if ok >= 1 else 0.0

def build_headline(parsed: dict) -> str:
    # ‡πÉ‡∏ä‡πâ name ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤ role ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠
    name = parsed.get("name", "Candidate")
    role = ""
    if parsed.get("experiences"):
        try:
            # ‡∏´‡∏≤ Role ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ end date ‡πÄ‡∏õ‡πá‡∏ô present ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ end date)
            latest_exp = sorted(parsed["experiences"], key=lambda x: str(x.get("end_date", x.get("end", "0"))), reverse=True)
            current_exp = [exp for exp in latest_exp if str(exp.get("end_date", exp.get("end", ""))).lower() == "present" or not exp.get("end_date", exp.get("end"))]
            
            if current_exp:
                 role = current_exp[0].get("title", current_exp[0].get("role", "")) # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á title/role
            elif latest_exp: # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏±‡∏ô present ‡πÄ‡∏≠‡∏≤‡∏≠‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                 role = latest_exp[0].get("title", latest_exp[0].get("role", ""))
        except Exception:
             # Fallback
             try:
                 role = parsed["experiences"][0].get("title", parsed["experiences"][0].get("role", ""))
             except (IndexError, TypeError):
                 role = "" # Handle empty experiences list or other errors

    # ‡πÉ‡∏ä‡πâ skills ‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß
    skills_list = (parsed.get("skills_normalized") or parsed.get("skills_raw") or parsed.get("skills") or [])[:3] # ‡πÄ‡∏≠‡∏≤ 3 ‡∏™‡∏Å‡∏¥‡∏•‡πÅ‡∏£‡∏Å
    skills_str = ", ".join(skills_list)
    return f"{name} ‚Äî {role or 'Candidate'}{f' | {skills_str}' if skills_str else ''}"


def redact_contacts(contacts: dict | None, enable: bool) -> dict | None:
    if not contacts:
        return None # ‡∏´‡∏£‡∏∑‡∏≠ {} ‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö Schema
    if not enable:
        return contacts
    safe = {}
    for k, v in contacts.items():
        is_pii = k.lower() in PII_KEYS
        has_value = isinstance(v, str) and v.strip()
        safe[k] = "‚Ä¢‚Ä¢‚Ä¢" if is_pii and has_value else v
    return safe

def build_evidence(parsed: dict, norm_skills: List[str]) -> Dict[str, List[str]]:
     return {} # Placeholder - ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà implement ‡∏Å‡∏≤‡∏£‡∏´‡∏≤ evidence ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

# === ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å API ===
def calculate_ucb_score(parsed_data: dict, jd_config: dict | None = None, redact_pii: bool = True) -> dict:
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô UCB ‡∏à‡∏≤‡∏Å Dictionary ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• parsed_resume
    Args:
        parsed_data: Dict ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô parsed_resume.json
        jd_config: Dict ‡∏Ç‡∏≠‡∏á Job Description (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ, ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÅ‡∏ó‡∏ô DEFAULT_JOB_REQ)
        redact_pii: True ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß
    Return:
        Dict ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå UCB Payload (fit_score, reasons, etc.)
    """
    global CURRENT_JOB_REQ
    if jd_config and isinstance(jd_config, dict):
        # ‡πÉ‡∏ä‡πâ JD ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (Merge ‡∏Å‡∏±‡∏ö Default)
        CURRENT_JOB_REQ = {**DEFAULT_JOB_REQ, **jd_config} 
        print(f"[INFO] Using provided JD config for scoring (Keys: {list(jd_config.keys())}).")
    else:
        # ‡πÉ‡∏ä‡πâ JD ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        CURRENT_JOB_REQ = DEFAULT_JOB_REQ.copy()
        print("[INFO] Using default JD config for scoring.")


    # --- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (Logic ‡πÄ‡∏î‡∏¥‡∏°‡∏à‡∏≤‡∏Å main) ---
    # (‡πÉ‡∏ä‡πâ skills ‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≤‡∏Å parsed_data ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤)
    norm_sk = parsed_data.get("skills", []) # ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏ñ‡∏π‡∏Å normalize ‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß
    # (Fallback ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏¢‡∏±‡∏á‡πÉ‡∏ä‡πâ key ‡πÄ‡∏Å‡πà‡∏≤)
    if not norm_sk and parsed_data.get("skills_normalized"):
         norm_sk = parsed_data.get("skills_normalized")
    if not norm_sk and parsed_data.get("skills_raw"): # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ normalized ‡πÄ‡∏•‡∏¢ ‡πÉ‡∏ä‡πâ raw
         norm_sk = normalize_skills(parsed_data.get("skills_raw")) # Normalize ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á

    print(f"[INFO] Scoring with {len(norm_sk)} normalized skills.") # Log ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏Å‡∏¥‡∏•

    # Sub-scores
    skills_score_raw, gaps, matched_skills = score_skills(norm_sk)
    # (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á key 'name' ‡πÅ‡∏•‡∏∞ 'full_name')
    # (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á key 'experiences' ‡πÅ‡∏•‡∏∞ 'experience')
    title_source = [parsed_data.get("name", parsed_data.get("full_name", ""))] + \
                   [e.get("title", e.get("role", "")) for e in (parsed_data.get("experiences", parsed_data.get("experience", [])) or [])]
    
    title_score_raw = score_title(title_source)
    years = estimate_years(parsed_data.get("experiences", parsed_data.get("experience", [])))
    exp_score_raw = min(1.0, years / 5.0) # üëà ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á: 5 ‡∏õ‡∏µ = 1.0 (‡∏à‡∏≤‡∏Å estimate_years)
    info_score_raw = score_contacts(parsed_data.get("contacts")) # (‡πÉ‡∏ä‡πâ contacts dict)

    # Weighted total
    weights = CURRENT_JOB_REQ.get("weights", DEFAULT_JOB_REQ["weights"])
    total_score = round(100 * (
        weights.get("skills", 0.40) * skills_score_raw +
        weights.get("experience", 0.20) * exp_score_raw +
        weights.get("title", 0.20) * title_score_raw +
        weights.get("contacts", 0.20) * info_score_raw
    ))
    total_score = max(0, min(100, total_score)) # Clamp 0-100

    print(f"[INFO] Sub-scores: Skills={skills_score_raw:.2f}, Exp={exp_score_raw:.2f}, Title={title_score_raw:.2f}, Contacts={info_score_raw:.2f}")


    # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (hr_view, machine_view) ---
    if total_score >= 85: level = "Excellent"
    elif total_score >= 70: level = "Strong"
    elif total_score >= 50: level = "Moderate"
    else: level = "Needs improvement"

    summary_details = {
        "matched_percent": round(skills_score_raw * 100),
        "evidence_count": 0, # Placeholder
        "evidence_bonus": 0, # Placeholder
        "matched_skills": matched_skills,
        "missing_skills": gaps,
        "missing_skills_detail": [{"skill": g, "impact_points": "?", "recommendation": "Consider training"} for g in gaps]
    }

    breakdown = []
    all_jd_skills = set(s.lower() for s in CURRENT_JOB_REQ.get("must_skills", []) + CURRENT_JOB_REQ.get("nice_skills", []))
    norm_sk_lower = set(s.lower() for s in norm_sk)
    for skill_lower in all_jd_skills:
         orig_skill = next((s for s in CURRENT_JOB_REQ.get("must_skills", []) + CURRENT_JOB_REQ.get("nice_skills", []) if s.lower() == skill_lower), skill_lower)
         skill_level = "Found" if skill_lower in norm_sk_lower else "Missing"
         breakdown.append({"skill": orig_skill, "level": skill_level})
    
    # (‡πÄ‡∏û‡∏¥‡πà‡∏° Other skills ‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏°‡∏µ)
    other_skills = [s for s in norm_sk if s.lower() not in all_jd_skills]
    for skill in other_skills[:10]: # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 10 ‡∏™‡∏Å‡∏¥‡∏•
        breakdown.append({"skill": skill, "level": "Other"})


    notes = []
    if years >= 3: notes.append(f"Relevant experience duration seems adequate (~{years} blocks).")
    elif years > 0: notes.append(f"Some experience detected (~{years} blocks).")
    else: notes.append("No relevant experience blocks found.")
    
    if title_score_raw > 0: notes.append("Keywords in name/roles match JD titles.")
    else: notes.append("No keywords in name/roles match JD titles.")

    if info_score_raw == 0: notes.append("Warning: Contact information (email/phone) missing.")
    
    if not norm_sk: notes.append("Warning: No skills extracted or normalized.")
    elif skills_score_raw == 0: notes.append("Skills found, but no match with JD.")


    hr_view = {
        "score": total_score,
        "level": level,
        "summary": summary_details,
        "breakdown": breakdown,
        "notes": notes,
        "score_components": { # üëà‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° Comma ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
            "Skills Match": round(skills_score_raw, 2),
            "Experience": round(exp_score_raw, 2),
            "Title Match": round(title_score_raw, 2),
            "Contact Info": round(info_score_raw, 2)
        }
    }

    machine_view = {
         "fit_score": round(skills_score_raw, 2),
         "gaps": gaps
    }

    evidence = build_evidence(parsed_data, norm_sk)
    safe_contacts = redact_contacts(parsed_data.get("contacts"), enable=redact_pii)

    final_payload = {
        "candidate_id": parsed_data.get("candidate_id", parsed_data.get("resume_id", os.path.splitext(os.path.basename(parsed_data.get("source_file","unknown")))[0])),
        "headline": build_headline(parsed_data),
        "skills_info": {"normalized": norm_sk, "raw": parsed_data.get("skills_raw", parsed_data.get("skills", []))},
        "contacts": safe_contacts,
        "fit_score_total": total_score,
        "reasons": notes, # üëà (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô) ‡πÉ‡∏ä‡πâ notes ‡πÅ‡∏ó‡∏ô reasons ‡πÄ‡∏î‡∏¥‡∏°
        "gaps_must": gaps,
        "evidence": evidence,
        "meta": {
            "generated_at": None, # Should be: datetime.now().isoformat()
            "schema_version": "1.2.0", # (‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï version)
            "jd_source": str(jd_config) if jd_config else "default"
        },
        "hr_view": hr_view,
        "machine_view": machine_view
    }

    print(f"[OK] Calculated score: {total_score}")
    return final_payload
# === ‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà ===


# === ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô main ‡πÄ‡∏î‡∏¥‡∏° (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡∏ú‡πà‡∏≤‡∏ô Terminal) ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏≠‡∏¢‡∏π‡πà ===
def main():
    ap = argparse.ArgumentParser(description="Generate UCB payload with fit_score + evidence")
    ap.add_argument("--in",  dest="inp",  required=True, help="path to parsed_resume.json")
    ap.add_argument("--out", dest="out", required=True, help="path to ucb_payload.json")
    ap.add_argument("--redact", action="store_true", default=False, help="‡∏ã‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß")
    ap.add_argument("--no-redact", dest="redact", action="store_false")
    ap.add_argument("--jd", type=str, default=None, help="path to JD config YAML (optional)")
    args = ap.parse_args()

    # --- ‡πÇ‡∏´‡∏•‡∏î JD config ---
    jd_cfg_dict = None
    if args.jd:
        try:
            with open(args.jd, "r", encoding="utf-8") as f:
                jd_cfg_dict = yaml.safe_load(f)
                if not isinstance(jd_cfg_dict, dict):
                     print(f"‚ö†Ô∏è Warning: JD file '{args.jd}' is not a valid dictionary. Using default JD.")
                     jd_cfg_dict = None
                else:
                     print(f"[INFO] Loaded JD config from {args.jd}")
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading JD config from '{args.jd}': {e}. Using default JD.")
            jd_cfg_dict = None

    # --- ‡πÇ‡∏´‡∏•‡∏î Parsed Resume ---
    try:
        input_path = Path(args.inp)
        if not input_path.exists():
             raise FileNotFoundError(f"Input file not found at {args.inp}")
        parsed = json.load(open(input_path, "r", encoding="utf-8"))
    except Exception as e:
        print(f"[-] Error loading parsed resume from '{args.inp}': {e}")
        return

    # --- ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ---
    try:
        # (Normalize skills ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô main ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ calculate_ucb_score)
        raw_skills = parsed.get("skills_raw", parsed.get("skills", [])) # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö c·∫£ 2 keys
        norm_sk = normalize_skills(raw_skills)
        parsed["skills"] = norm_sk # üëà ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï skills ‡πÉ‡∏ô parsed dict ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß
        parsed["skills_normalized"] = norm_sk # (‡πÄ‡∏ú‡∏∑‡πà‡∏≠ schema 0.2.0)
        parsed["skills_raw"] = raw_skills # (‡πÄ‡∏Å‡πá‡∏ö raw ‡πÑ‡∏ß‡πâ)

        payload = calculate_ucb_score(parsed, jd_config=jd_cfg_dict, redact_pii=args.redact)
        total = payload.get("fit_score_total", 0)

        # --- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ---
        output_path = Path(args.out)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        json.dump(payload, open(output_path, "w", encoding="utf-8"), ensure_ascii=False, indent=2)
        print(f"[OK] score={total} -> {args.out}  (redact={'on' if args.redact else 'off'})") # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç \u2192

    except Exception as e:
         print(f"[-] Error calculating UCB score: {e}")
         import traceback
         traceback.print_exc() # ‡∏û‡∏¥‡∏°‡∏û‡πå Error ‡πÄ‡∏ï‡πá‡∏°‡πÜ ‡∏ï‡∏≠‡∏ô‡∏£‡∏±‡∏ô Terminal


if __name__ == "__main__":
    try:
        import yaml
    except ImportError:
        print(f"[-] Error: PyYAML is required to load JD config. Please run 'pip install pyyaml'")
        yaml = None

    main()